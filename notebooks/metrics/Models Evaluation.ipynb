{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a41309-47ae-4fa4-ba82-72ea3fc3bb3d",
   "metadata": {},
   "source": [
    "# Models Evaluation\n",
    "\n",
    "Now as last step, previous to the deployment of the best model is the evaluation of all the trained models using the test dataset. Based on that the model with the best performance will be selected for the deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885f7c5",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c309a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b590c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from src.metrics.models_metrics import print_sklearn_model_metrics\n",
    "from src.processing.features_building import build_features\n",
    "from src.utils.obesity_encoder import ENCODER_NOBESITY, get_class_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a5c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b26f0",
   "metadata": {},
   "source": [
    "## Constants Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f3746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/'\n",
    "RAW_PATH = DATA_PATH + 'raw/'\n",
    "PROCESSED_PATH = DATA_PATH + 'processed/'\n",
    "\n",
    "RESULTS_PATH = '../../results/'\n",
    "MODELS_PATH = RESULTS_PATH + 'models/'\n",
    "PREDICTIONS_PATH = RESULTS_PATH + 'predictions/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f22b518",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984841aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(RAW_PATH + 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210a4de-8bfc-48bb-b10b-36e306a32b6c",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b2a10c-ae65-4efd-aa71-5361be527029",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = test_df.pop('id')\n",
    "test_df = build_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53545d-4c2a-49c9-87ab-387dec23985b",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34092dff-ad18-4809-8906-dd50ad21ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + 'model.logreg.pkl', 'rb') as file:\n",
    "    logreg = pickle.load(file)\n",
    "\n",
    "with open(MODELS_PATH + 'model.xgboost.pkl', 'rb') as file:\n",
    "    xgboost = pickle.load(file)\n",
    "\n",
    "with open(MODELS_PATH + 'model.rf.pkl', 'rb') as file:\n",
    "    rf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982376f-ece2-4abd-a786-0c099cd0333b",
   "metadata": {},
   "source": [
    "## Test Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791e2ab-35ca-420d-835e-cbb6d39642d8",
   "metadata": {},
   "source": [
    "As the test dataset does not have the target column we will evaluate the models using the Kaggle competition of this [link](https://www.kaggle.com/competitions/playground-series-s4e2/). For it we will format the predictions in the expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4cf9ca-d4e8-4acc-9498-e1941aaa8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg.predict(test_df)\n",
    "logreg_submission_df = pd.DataFrame(\n",
    "    data = id_col,\n",
    "    columns = ['id'] \n",
    ")\n",
    "\n",
    "logreg_submission_df['NObesydad_encoded'] = y_pred_logreg\n",
    "logreg_submission_df['NObesydad'] = logreg_submission_df.apply(\n",
    "    lambda row: get_class_encoder(ENCODER_NOBESITY, row.NObesydad_encoded), axis= 1\n",
    ")\n",
    "logreg_submission_df.drop(['NObesydad_encoded'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc9227b-adb2-4a58-bc2b-e2b61e776603",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_submission_df.to_csv(PREDICTIONS_PATH + 'logreg_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13612596-b171-47ea-8f7e-7b0078e58e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(test_df)\n",
    "rf_submission_df = pd.DataFrame(\n",
    "    data = id_col,\n",
    "    columns = ['id'] \n",
    ")\n",
    "\n",
    "rf_submission_df['NObesydad_encoded'] = y_pred_rf\n",
    "rf_submission_df['NObesydad'] = rf_submission_df.apply(\n",
    "    lambda row: get_class_encoder(ENCODER_NOBESITY, row.NObesydad_encoded), axis= 1\n",
    ")\n",
    "rf_submission_df.drop(['NObesydad_encoded'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e546502d-10f0-45c6-9c36-10ddb839c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_submission_df.to_csv(PREDICTIONS_PATH + 'rf_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca41589-a83d-45f8-8533-de267bdfbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgboost = xgboost.predict(test_df)\n",
    "xgboost_submission_df = pd.DataFrame(\n",
    "    data = id_col,\n",
    "    columns = ['id'] \n",
    ")\n",
    "\n",
    "xgboost_submission_df['NObesydad_encoded'] = y_pred_xgboost\n",
    "xgboost_submission_df['NObesydad'] = xgboost_submission_df.apply(\n",
    "    lambda row: get_class_encoder(ENCODER_NOBESITY, row.NObesydad_encoded), axis= 1\n",
    ")\n",
    "xgboost_submission_df.drop(['NObesydad_encoded'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a10fe0-93bd-4996-9a50-e17a0fccc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_submission_df.to_csv(PREDICTIONS_PATH + 'xgboost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8044cca-b2d8-48da-931e-81af5dff3428",
   "metadata": {},
   "source": [
    "## Kaggle Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876204e5-f208-4d1b-8734-2f22f1f3dc52",
   "metadata": {},
   "source": [
    "![Results](../../public/imgs/Kaggle_Submission_Classic_Models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2167dff-795b-4107-8de2-b0deb9f3f333",
   "metadata": {},
   "source": [
    "All the models performed proficiently at the kaggle evaluation, but the best one was the Random Forest, so it will be the model to deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2dfa5-929a-4f2f-986d-524599115504",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "As the models performed well in training and test dataset, taking a look at the feature importance that each model is defining is a really good insight to understand better the behaviour of those."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
